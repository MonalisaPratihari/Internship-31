{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c13ba5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\shrihan manit\\anaconda3\\lib\\site-packages (4.4.3)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\shrihan manit\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\shrihan manit\\anaconda3\\lib\\site-packages (from selenium) (0.21.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\shrihan manit\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\shrihan manit\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: idna in c:\\users\\shrihan manit\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\shrihan manit\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\shrihan manit\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\shrihan manit\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\shrihan manit\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\shrihan manit\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\shrihan manit\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\shrihan manit\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\shrihan manit\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\shrihan manit\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\shrihan manit\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n"
     ]
    }
   ],
   "source": [
    "# Let's first install the selenium library\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9009f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now import all the required libraries\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8349d052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Shrihan Manit\\OneDrive\\Desktop\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb54628",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You \n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 \n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e3651c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8386adbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering designation as required in the question\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85ab3ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering location as required\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a020c19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d6433b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list to store data the scraped data\n",
    "job_title = []\n",
    "job_location =[]\n",
    "company_name = []\n",
    "experience_required =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9e6554a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Analyst',\n",
       " 'Senior Data Analyst - Data Modeling/Quality',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst/Data Engineer',\n",
       " 'Contractual Hiring For Top MNC || Business Data Analyst || Bangalore',\n",
       " 'Data Analytics and Interpretation Business Analyst',\n",
       " 'Data Analyst 2',\n",
       " 'Sr. Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst - India & Singapore']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "# Scraping Job title from the given page\n",
    "title_tags= driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b186ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Kolkata, Hyderabad/Secunderabad, Pune, Chennai, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Remote',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Singapore, Gurgaon/Gurugram, Mumbai (All Areas)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "# Scraping Job Location from the given page\n",
    "location_tags= driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5e1e83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mobile Premier League',\n",
       " 'Get My Parking',\n",
       " 'Walmart',\n",
       " 'Tech Mahindra',\n",
       " 'TeamLease',\n",
       " 'Accenture',\n",
       " 'Zynga',\n",
       " 'McAfee',\n",
       " 'TMF Group',\n",
       " 'Course5']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "# Scraping Company name from the given page\n",
    "company_tags= driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "986e3da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3-5 Yrs',\n",
       " '4-9 Yrs',\n",
       " '4-7 Yrs',\n",
       " '4-9 Yrs',\n",
       " '5-8 Yrs',\n",
       " '6-8 Yrs',\n",
       " '2-7 Yrs',\n",
       " '5-7 Yrs',\n",
       " '4-9 Yrs',\n",
       " '3-8 Yrs']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "# Scraping Job Experience from the given page\n",
    "experience_tags= driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)\n",
    "experience_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17db26af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ecc1975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Mobile Premier League</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst - Data Modeling/Quality</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Get My Parking</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst/Data Engineer</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Contractual Hiring For Top MNC || Business Dat...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>TeamLease</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analytics and Interpretation Business Ana...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst 2</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Zynga</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Remote</td>\n",
       "      <td>McAfee</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>TMF Group</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Analyst - India &amp; Singapore</td>\n",
       "      <td>Bangalore/Bengaluru, Singapore, Gurgaon/Gurugr...</td>\n",
       "      <td>Course5</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                                Senior Data Analyst   \n",
       "1        Senior Data Analyst - Data Modeling/Quality   \n",
       "2                                Senior Data Analyst   \n",
       "3                         Data Analyst/Data Engineer   \n",
       "4  Contractual Hiring For Top MNC || Business Dat...   \n",
       "5  Data Analytics and Interpretation Business Ana...   \n",
       "6                                     Data Analyst 2   \n",
       "7                                   Sr. Data Analyst   \n",
       "8                                Senior Data Analyst   \n",
       "9            Senior Data Analyst - India & Singapore   \n",
       "\n",
       "                                        Job_location           Company_name  \\\n",
       "0                                Bangalore/Bengaluru  Mobile Premier League   \n",
       "1                                Bangalore/Bengaluru         Get My Parking   \n",
       "2                                Bangalore/Bengaluru                Walmart   \n",
       "3  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...          Tech Mahindra   \n",
       "4                                Bangalore/Bengaluru              TeamLease   \n",
       "5                                Bangalore/Bengaluru              Accenture   \n",
       "6                                Bangalore/Bengaluru                  Zynga   \n",
       "7                                             Remote                 McAfee   \n",
       "8                                Bangalore/Bengaluru              TMF Group   \n",
       "9  Bangalore/Bengaluru, Singapore, Gurgaon/Gurugr...                Course5   \n",
       "\n",
       "  Exp_required  \n",
       "0      3-5 Yrs  \n",
       "1      4-9 Yrs  \n",
       "2      4-7 Yrs  \n",
       "3      4-9 Yrs  \n",
       "4      5-8 Yrs  \n",
       "5      6-8 Yrs  \n",
       "6      2-7 Yrs  \n",
       "7      5-7 Yrs  \n",
       "8      4-9 Yrs  \n",
       "9      3-8 Yrs  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the dataframe from above data\n",
    "df = pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name,'Exp_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9091517a",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You \n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc2de827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6a15324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering \"Data Scientist\" in skills/designations/companies\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efd7c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering location as Bangalore\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a50e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[6]\")\n",
    "search.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d538bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list to store data the scraped data\n",
    "job_title = []\n",
    "job_location =[]\n",
    "company_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9393a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Job Opportunity on Data Science_ Python with Techmahindra',\n",
       " 'Assistant Manager - Data Science',\n",
       " 'Analystics & Modeling Specialist',\n",
       " 'Hiring For DATA Scientist @ NTT DATA Business Solution India',\n",
       " 'Data Scientist/AIML Engineer',\n",
       " 'ACN - Applied Intelligence - Data & Insights - CPG - 09',\n",
       " 'Data Scientist',\n",
       " 'Lead ML Scientist',\n",
       " 'Tcs Hiring For Data Scientist',\n",
       " 'Data Scientist - II']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "# Scraping Job title from the given page\n",
    "title_tags= driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9031d98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru, Kolkata, Hyderabad/Secunderabad, Pune, Chennai, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru, Mumbai, Pune',\n",
       " 'Bangalore/Bengaluru, Kolkata, Mumbai, Hyderabad/Secunderabad, Pune, Chennai, delhi ncr',\n",
       " 'Bangalore/Bengaluru, Noida, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru, Mumbai, Hyderabad/Secunderabad',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Mumbai',\n",
       " 'Bangalore/Bengaluru, Chennai, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru, India, Mumbai (All Areas)']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "# Scraping Job Location from the given page\n",
    "location_tags= driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "478bf2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tech Mahindra',\n",
       " 'CitiusTech',\n",
       " 'Accenture',\n",
       " 'NTT DATA Business Solutions Private Limited',\n",
       " 'upGrad',\n",
       " 'Accenture',\n",
       " 'IBM',\n",
       " 'Fractal Analytics',\n",
       " 'TATA CONSULTANCY SERVICES (TCS)',\n",
       " 'Bizongo']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "# Scraping Company name from the given page\n",
    "company_tags= driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f963d883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01046a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job Opportunity on Data Science_ Python with T...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist/AIML Engineer</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>upGrad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACN - Applied Intelligence - Data &amp; Insights -...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead ML Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tcs Hiring For Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai, Mumbai (All Areas)</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - II</td>\n",
       "      <td>Bangalore/Bengaluru, India, Mumbai (All Areas)</td>\n",
       "      <td>Bizongo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0  Job Opportunity on Data Science_ Python with T...   \n",
       "1                   Assistant Manager - Data Science   \n",
       "2                   Analystics & Modeling Specialist   \n",
       "3  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "4                       Data Scientist/AIML Engineer   \n",
       "5  ACN - Applied Intelligence - Data & Insights -...   \n",
       "6                                     Data Scientist   \n",
       "7                                  Lead ML Scientist   \n",
       "8                      Tcs Hiring For Data Scientist   \n",
       "9                                Data Scientist - II   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "1                  Bangalore/Bengaluru, Mumbai, Pune   \n",
       "2  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "3  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "4  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                        Bangalore/Bengaluru, Mumbai   \n",
       "8   Bangalore/Bengaluru, Chennai, Mumbai (All Areas)   \n",
       "9     Bangalore/Bengaluru, India, Mumbai (All Areas)   \n",
       "\n",
       "                                  Company_name  \n",
       "0                                Tech Mahindra  \n",
       "1                                   CitiusTech  \n",
       "2                                    Accenture  \n",
       "3  NTT DATA Business Solutions Private Limited  \n",
       "4                                       upGrad  \n",
       "5                                    Accenture  \n",
       "6                                          IBM  \n",
       "7                            Fractal Analytics  \n",
       "8              TATA CONSULTANCY SERVICES (TCS)  \n",
       "9                                      Bizongo  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the dataframe from above data\n",
    "df = pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee092e3",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required. \n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1dc95d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fae35b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering \"Data Scientist\" in skills/designations/companies\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b71cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering location as Bangalore\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Delhi/NCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "174a9300",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[6]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbcc828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "# Since job_location is Delhi/NCR a single element applied absolute XPATH\n",
    "job_location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[13]/div[2]/div[2]/label/p/span[1]\")\n",
    "job_location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "599f52ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since salary is 3-6 Lakhs a single element applied absolute XPATH\n",
    "salary = driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/p/span[1]\")\n",
    "salary.click()\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1cd28eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list to store data the scraped data\n",
    "job_title = []\n",
    "job_location =[]\n",
    "company_name = []\n",
    "experience_required =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49b06532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist - Predictive Analytics',\n",
       " 'Data Scientist',\n",
       " 'Data scientist- Python',\n",
       " 'Urgent Hiring- Expertise in Data Scientist in Gurgaon & Bangalore',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "# Scraping Job title from the given page\n",
    "title_tags= driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a582a3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gurgaon/Gurugram',\n",
       " 'Gurgaon/Gurugram, Dehradun, Hyderabad/Secunderabad',\n",
       " 'Gurgaon/Gurugram, Noida, Mumbai, Chandigarh, Hyderabad/Secunderabad, Pune, Chennai, Coimbatore, Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Gurgaon/Gurugram']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "# Scraping Job Location from the given page\n",
    "location_tags= driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "819af2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Optum',\n",
       " 'torcai digital media',\n",
       " 'Confidential',\n",
       " 'Feedback Infra',\n",
       " 'TeamPlus Staffing Solution Pvt Ltd',\n",
       " 'CLARITY CONSULTING',\n",
       " 'AR Consultant']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "# Scraping Company name from the given page\n",
    "company_tags= driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3772795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2-7 Yrs', '2-7 Yrs', '1-6 Yrs', '2-4 Yrs', '3-6 Yrs', '3-8 Yrs', '2-5 Yrs']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "# Scraping Job Experience from the given page\n",
    "experience_tags= driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)\n",
    "experience_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98d70374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7 7 7\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c05d1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Dehradun, Hyderabad/Secunder...</td>\n",
       "      <td>torcai digital media</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Predictive Analytics</td>\n",
       "      <td>Gurgaon/Gurugram, Noida, Mumbai, Chandigarh, H...</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Feedback Infra</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data scientist- Python</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>TeamPlus Staffing Solution Pvt Ltd</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Urgent Hiring- Expertise in Data Scientist in ...</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi /...</td>\n",
       "      <td>CLARITY CONSULTING</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>AR Consultant</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                                     Data Scientist   \n",
       "1                                     Data Scientist   \n",
       "2              Data Scientist - Predictive Analytics   \n",
       "3                                     Data Scientist   \n",
       "4                             Data scientist- Python   \n",
       "5  Urgent Hiring- Expertise in Data Scientist in ...   \n",
       "6                                     Data Scientist   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0                                   Gurgaon/Gurugram   \n",
       "1  Gurgaon/Gurugram, Dehradun, Hyderabad/Secunder...   \n",
       "2  Gurgaon/Gurugram, Noida, Mumbai, Chandigarh, H...   \n",
       "3                                   Gurgaon/Gurugram   \n",
       "4                                   Gurgaon/Gurugram   \n",
       "5  Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi /...   \n",
       "6                                   Gurgaon/Gurugram   \n",
       "\n",
       "                         Company_name Exp_required  \n",
       "0                               Optum      2-7 Yrs  \n",
       "1                torcai digital media      2-7 Yrs  \n",
       "2                        Confidential      1-6 Yrs  \n",
       "3                      Feedback Infra      2-4 Yrs  \n",
       "4  TeamPlus Staffing Solution Pvt Ltd      3-6 Yrs  \n",
       "5                  CLARITY CONSULTING      3-8 Yrs  \n",
       "6                       AR Consultant      2-5 Yrs  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the dataframe from above data\n",
    "df = pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name,'Exp_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8fd74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23cfaa91",
   "metadata": {},
   "source": [
    "Q4 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "\n",
    "Brand Product Description Price To scrape the data you have to go through following steps: Go to flipkart webpage by url https://www.flipkart.com/ Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon after that you will reach to a webpage having a lot of sunglasses. From this page you can scrap the required data as usual. after scraping data from the first page, go to the “Next” Button at the bottom of the page , then click on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f03416d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Shrihan Manit\\OneDrive\\Desktop\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "becec911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the flipkart on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5e181df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering product in search bar as required\n",
    "product = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys('Sunglasses')\n",
    "\n",
    "time.sleep(3)\n",
    "# Serching Item\n",
    "search = driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "427ada22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the empty list\n",
    "Brand = []\n",
    "Product_Description = []\n",
    "Price = []\n",
    "Discount = []\n",
    " \n",
    "time.sleep(3)\n",
    "\n",
    "#Scrapping the required details\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')      \n",
    "    for i in brand_tags:\n",
    "        Brand.append(i.text)     \n",
    "        \n",
    "    Product_Desc_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')     \n",
    "    for i in Product_Desc_tags:\n",
    "        Product_Description.append(i.text)    \n",
    "        \n",
    "    Price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]') \n",
    "    for i in Price_tags:\n",
    "        Price.append(i.text)\n",
    "        \n",
    "    Discount_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in Discount_tags:\n",
    "        Discount.append(i.text)\n",
    "        \n",
    "    nxt_button=driver.find_elements(By.XPATH,\"//a[@class='_1LKTO3']\")\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href')) \n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e87a301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Product_Description),len(Price),len(Discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3dee397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Desc</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹319</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Retro Squ...</td>\n",
       "      <td>₹901</td>\n",
       "      <td>54% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>UV Protection Oval Sunglasses (55)</td>\n",
       "      <td>₹301</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mi</td>\n",
       "      <td>Polarized Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "      <td>33% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹359</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wrap-around Sunglasses (63)</td>\n",
       "      <td>₹710</td>\n",
       "      <td>21% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Round Sun...</td>\n",
       "      <td>₹764</td>\n",
       "      <td>61% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lee Topper</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹219</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection, Polarized Round Sunglasses (54)</td>\n",
       "      <td>₹538</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                       Product_Desc Price  \\\n",
       "0         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹799   \n",
       "1   ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...  ₹319   \n",
       "2    VINCENT CHASE  by Lenskart Polarized, UV Protection Retro Squ...  ₹901   \n",
       "3         Roadster                 UV Protection Oval Sunglasses (55)  ₹301   \n",
       "4               Mi           Polarized Aviator Sunglasses (Free Size)  ₹799   \n",
       "..             ...                                                ...   ...   \n",
       "95  ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...  ₹359   \n",
       "96        Fastrack          UV Protection Wrap-around Sunglasses (63)  ₹710   \n",
       "97   VINCENT CHASE  by Lenskart Polarized, UV Protection Round Sun...  ₹764   \n",
       "98      Lee Topper   UV Protection Rectangular Sunglasses (Free Size)  ₹219   \n",
       "99       ROYAL SON     UV Protection, Polarized Round Sunglasses (54)  ₹538   \n",
       "\n",
       "   Discount  \n",
       "0   20% off  \n",
       "1   84% off  \n",
       "2   54% off  \n",
       "3   72% off  \n",
       "4   33% off  \n",
       "..      ...  \n",
       "95  82% off  \n",
       "96  21% off  \n",
       "97  61% off  \n",
       "98  78% off  \n",
       "99  73% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe from the above data\n",
    "df = pd.DataFrame({'Brand':Brand[:100],'Product_Desc':Product_Description[:100],'Price':Price[:100],'Discount':Discount[:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eb6795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9a0751d",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field. You have to scrape 4 attributes of each sneaker:\n",
    "\n",
    "Brand Product Description Price Discount As shown in the below image, you have to scrape the tick marked attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04969462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Shrihan Manit\\OneDrive\\Desktop\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a051118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the flipkart on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "167900a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering product in search bar as required\n",
    "product = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys('Sneakers')\n",
    "\n",
    "time.sleep(3)\n",
    "# Serching Item\n",
    "search = driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5d32058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the empty list\n",
    "Brand = []\n",
    "Product_Description = []\n",
    "Price = []\n",
    "Discount = []\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "#Scrapping the required details\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')      \n",
    "    for i in brand_tags:\n",
    "        Brand.append(i.text)     \n",
    "        \n",
    "    Product_Desc_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')     \n",
    "    for i in Product_Desc_tags:\n",
    "        Product_Description.append(i.text)    \n",
    "        \n",
    "    Price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]') \n",
    "    for i in Price_tags:\n",
    "        Price.append(i.text)\n",
    "        \n",
    "    Discount_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in Discount_tags:\n",
    "        Discount.append(i.text)\n",
    "        \n",
    "    nxt_button=driver.find_elements(By.XPATH,\"//a[@class='_1LKTO3']\")\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href')) \n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7fc3520a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 115 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Product_Description),len(Price),len(Discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d77e3d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Desc</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹549</td>\n",
       "      <td>45% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Premium Casual Shoes for Men Sneakers For Men</td>\n",
       "      <td>₹199</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹199</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Latest Design Trendy and Comfortable Sports Sh...</td>\n",
       "      <td>₹199</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>STR2 Sneakers For Men</td>\n",
       "      <td>₹501</td>\n",
       "      <td>49% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>RONSON</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹599</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>KNIGHT WALKERS</td>\n",
       "      <td>Mesh Sneakers For Men</td>\n",
       "      <td>₹664</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ASTEROID</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>₹474</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GVR</td>\n",
       "      <td>Men's Casual Walking Partywear Sneakers Runnin...</td>\n",
       "      <td>₹599</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                       Product_Desc Price  \\\n",
       "0         RapidBox                                   Sneakers For Men  ₹549   \n",
       "1           BRUTON  Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...  ₹499   \n",
       "2            BIRDE      Premium Casual Shoes for Men Sneakers For Men  ₹199   \n",
       "3            BIRDE                      Casual Shoes Sneakers For Men  ₹199   \n",
       "4            BIRDE  Latest Design Trendy and Comfortable Sports Sh...  ₹199   \n",
       "..             ...                                                ...   ...   \n",
       "95        RapidBox                              STR2 Sneakers For Men  ₹501   \n",
       "96          RONSON                                   Sneakers For Men  ₹599   \n",
       "97  KNIGHT WALKERS                              Mesh Sneakers For Men  ₹664   \n",
       "98        ASTEROID      Modern Trendy Sneakers Shoes Sneakers For Men  ₹474   \n",
       "99             GVR  Men's Casual Walking Partywear Sneakers Runnin...  ₹599   \n",
       "\n",
       "   Discount  \n",
       "0   45% off  \n",
       "1   85% off  \n",
       "2   80% off  \n",
       "3   80% off  \n",
       "4   80% off  \n",
       "..      ...  \n",
       "95  49% off  \n",
       "96  70% off  \n",
       "97  66% off  \n",
       "98  52% off  \n",
       "99  40% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe from the above data\n",
    "df = pd.DataFrame({'Brand':Brand[:100],'Product_Desc':Product_Description[:100],'Price':Price[:100],'Discount':Discount[:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbb84c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41cf5e18",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes Set second Price filter and Color filter to “Black”, as shown in the below image.\n",
    "\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb99f3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Shrihan Manit\\OneDrive\\Desktop\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "971db407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the Myntra website on automated chrome browser\n",
    "driver.get(\"https://www.myntra.com/shoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8b090b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(4)\n",
    "\n",
    "#clicking on price filter\n",
    "pricebutton = driver.find_element(By.XPATH,\"//ul[@class='price-list']/li[2]/label/div\")\n",
    "pricebutton.click()\n",
    "\n",
    "#clicking on black colour \n",
    "blackbutton = driver.find_element(By.XPATH,'//li[@class=\"colour-listItem\"]/label/div')\n",
    "blackbutton.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a97ca563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the empty list\n",
    "Brand = []\n",
    "Product_Description = []\n",
    "Price = []\n",
    "\n",
    "#Scrapping the required details\n",
    "start=0\n",
    "end=2\n",
    "for page in range(start,end):\n",
    "    brand_tags=driver.find_elements(By.XPATH,\"//div[@class='product-productMetaInfo']\")      \n",
    "    for i in brand_tags:\n",
    "        Brand.append(i.text)     \n",
    "        \n",
    "    Product_Desc_tags=driver.find_elements(By.XPATH,\"//div[@class='product-productMetaInfo']/h4[1]\")     \n",
    "    for i in Product_Desc_tags:\n",
    "        Product_Description.append(i.text)    \n",
    "        \n",
    "    Price_tags=driver.find_elements(By.XPATH,'//div[@class=\"product-price\"]') \n",
    "    for i in Price_tags:\n",
    "        Price.append(i.text) \n",
    "        \n",
    "        nxt_button=driver.find_elements(By.XPATH,'//a[@rel=\"next\"]')\n",
    "\n",
    "try:\n",
    "    driver.get(nxt_button[1].get_attribute('href')) \n",
    "except:\n",
    "    driver.get(nxt_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1e72c3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Product_Description),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c36a8363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Desc</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Red Tape\\nMen Walking Shoes\\nRs. 1187Rs. 5399(...</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Rs. 1187Rs. 5399(78% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puma\\nMen Cell Vive Elevate Running\\nRs. 2599R...</td>\n",
       "      <td>Men Cell Vive Elevate Running</td>\n",
       "      <td>Rs. 2599Rs. 6499(60% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Red Tape\\nMen Walking Shoes\\nRs. 1165Rs. 5299(...</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Rs. 1165Rs. 5299(78% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roadster\\nMen Sneakers\\nRs. 796Rs. 3795(79% OFF)</td>\n",
       "      <td>Men Sneakers</td>\n",
       "      <td>Rs. 796Rs. 3795(79% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puma\\nMen LQDCELL Running Shoes\\nRs. 2799Rs. 6...</td>\n",
       "      <td>Men LQDCELL Running Shoes</td>\n",
       "      <td>Rs. 2799Rs. 6999(60% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Campus\\nMen Running Shoes\\nRs. 779Rs. 1299(40%...</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 779Rs. 1299(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Red Tape\\nMen Walking Shoes\\nRs. 1143Rs. 5199(...</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Rs. 1143Rs. 5199(78% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Skechers\\nMen Max Cushioning Running\\nRs. 6749...</td>\n",
       "      <td>Men Max Cushioning Running</td>\n",
       "      <td>Rs. 6749Rs. 8999(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>HRX by Hrithik Roshan\\nMen Out Back Outdoor Sh...</td>\n",
       "      <td>Men Out Back Outdoor Shoes</td>\n",
       "      <td>Rs. 1739Rs. 5799(70% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Monrow\\nWomen Sandals\\nRs. 988Rs. 2299(57% OFF)</td>\n",
       "      <td>Women Sandals</td>\n",
       "      <td>Rs. 988Rs. 2299(57% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Brand  \\\n",
       "0   Red Tape\\nMen Walking Shoes\\nRs. 1187Rs. 5399(...   \n",
       "1   Puma\\nMen Cell Vive Elevate Running\\nRs. 2599R...   \n",
       "2   Red Tape\\nMen Walking Shoes\\nRs. 1165Rs. 5299(...   \n",
       "3    Roadster\\nMen Sneakers\\nRs. 796Rs. 3795(79% OFF)   \n",
       "4   Puma\\nMen LQDCELL Running Shoes\\nRs. 2799Rs. 6...   \n",
       "..                                                ...   \n",
       "95  Campus\\nMen Running Shoes\\nRs. 779Rs. 1299(40%...   \n",
       "96  Red Tape\\nMen Walking Shoes\\nRs. 1143Rs. 5199(...   \n",
       "97  Skechers\\nMen Max Cushioning Running\\nRs. 6749...   \n",
       "98  HRX by Hrithik Roshan\\nMen Out Back Outdoor Sh...   \n",
       "99    Monrow\\nWomen Sandals\\nRs. 988Rs. 2299(57% OFF)   \n",
       "\n",
       "                     Product_Desc                      Price  \n",
       "0               Men Walking Shoes  Rs. 1187Rs. 5399(78% OFF)  \n",
       "1   Men Cell Vive Elevate Running  Rs. 2599Rs. 6499(60% OFF)  \n",
       "2               Men Walking Shoes  Rs. 1165Rs. 5299(78% OFF)  \n",
       "3                    Men Sneakers   Rs. 796Rs. 3795(79% OFF)  \n",
       "4       Men LQDCELL Running Shoes  Rs. 2799Rs. 6999(60% OFF)  \n",
       "..                            ...                        ...  \n",
       "95              Men Running Shoes   Rs. 779Rs. 1299(40% OFF)  \n",
       "96              Men Walking Shoes  Rs. 1143Rs. 5199(78% OFF)  \n",
       "97     Men Max Cushioning Running  Rs. 6749Rs. 8999(25% OFF)  \n",
       "98     Men Out Back Outdoor Shoes  Rs. 1739Rs. 5799(70% OFF)  \n",
       "99                  Women Sandals   Rs. 988Rs. 2299(57% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe from the above data\n",
    "df = pd.DataFrame({'Brand':Brand[:100],'Product_Desc':Product_Description[:100],'Price':Price[:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525e0751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1b30da7",
   "metadata": {},
   "source": [
    "Q8: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” as shown in the below image: After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "\n",
    "Title\n",
    "Ratings\n",
    "Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ec4e3689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Shrihan Manit\\OneDrive\\Desktop\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9d574b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the amazon website on automated chrome browser\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0ff14dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering product \"Laptop\" in search bar as required\n",
    "product=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "product.send_keys('Laptop')\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# Serching Item\n",
    "search = driver.find_element(By.ID,\"nav-search-submit-button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "38214ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we need to apply in search CPU type “Intel Core i7”\n",
    "CPU_intel_core_i7= driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[8]/ul[5]/li[13]/span/a/span\")\n",
    "CPU_intel_core_i7.click()\n",
    "\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "96e15576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list to store the scraped data\n",
    "Title = []\n",
    "Ratings =[]\n",
    "Price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8e802092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Acer Spin 5 Professional Laptop with Alexa Built-in and Active Stylus Pen (12th Gen Intel Core i7/16GB RAM/1 TB SSD) SP514-51N, 1.3 KG',\n",
       " 'Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 15.6\" (39.62cm) FHD IPS Thin & Light Laptop (16GB/512GB SSD/Windows 11/Office 2021/Backlit/FPR/3months Game Pass/Storm Grey/1.85Kg), 82SF008WIN',\n",
       " 'Lenovo ThinkBook 15 Intel 11th Gen Core i7 15.6\"(39.62 cm)FHD Thin and Light Laptop (16GB/512GB SSD/Windows 11 Home/MS Office H&S 2021/Iris® Xe Graphics/Backlit/Mineral Grey/1.7 Kg) 20VE00W4IH',\n",
       " 'Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 15.6\" (39.62cm) FHD IPS Thin & Light Laptop (16GB/512GB SSD/Windows 11/Office 2021/Backlit/FPR/3months Game Pass/Storm Grey/1.85Kg), 82SF008WIN',\n",
       " 'Lenovo IdeaPad Gaming 3 Intel Core i7 10th Gen 15.6\" (39.62cm) FHD IPS Gaming Laptop (8GB/512GB SSD/4GB NVIDIA GTX 1650/120Hz/Windows 10/Backlit Keyboard/Onyx Black/2.2Kg), 81Y4019EIN',\n",
       " 'Lenovo Yoga 7i 11th Gen Intel Core i7-1165G7 14 inches FHD IPS 2-in-1 Touchscreen Business Laptop (16GB/512GB SSD/Windows 10/MS Office/Digital Pen/Fingerprint Reader/Slate Grey/1.43Kg), 82BH004HIN',\n",
       " 'ASUS Zenbook 13 OLED, 13.3-inch (33.78 cms) FHD OLED, Intel Core i7-1165G7 11th Gen, Thin and Light Laptop (16GB/512GB SSD/Iris Xe Graphics/Windows 11/Office 2021/Grey/1.14 kg), UX325EA-KG722WS',\n",
       " '(Renewed) HP ELITEBOOK X360 1030 G4 (CORE I7 8TH/16GB/512GB SSD/WEBCAM/13.3\" TOUCH/WIN PRO)',\n",
       " '(Renewed) Lenovo Intel Core i7 5600U 12.5-Inch (31.75 cms) HD (1366 X 768) Laptop (8 GB/256 GB SSD/Windows 10/Intel HD 5500//1.53 Kg), Lenovo X250',\n",
       " '(Renewed) HP Elitebook 840G1-i7-8 GB-2 TB 14-inch Touch Screen Laptop (4th Gen Core i7/8GB/2TB/Windows 10/Integrated Graphics), Black']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "# Scraping Title from the given page\n",
    "title_tags= driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    Title.append(title)\n",
    "Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fa6ca69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Ratings from the given page\n",
    "rating_tags= driver.find_elements(By.XPATH,'//span[@class=\"a-icon-alt\"]')\n",
    "for i in rating_tags[0:10]:\n",
    "    rating =i.text\n",
    "    Ratings.append(rating)\n",
    "Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cb9c2d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,24,490',\n",
       " '82,990',\n",
       " '80,950',\n",
       " '82,990',\n",
       " '78,990',\n",
       " '1,06,800',\n",
       " '79,990',\n",
       " '47,890',\n",
       " '23,997',\n",
       " '41,690']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Price from the given page\n",
    "price_tags= driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in price_tags[0:10]:\n",
    "    price =i.text\n",
    "    Price.append(price)\n",
    "Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "44096957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(Title),len(Ratings),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6434ea19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acer Spin 5 Professional Laptop with Alexa Bui...</td>\n",
       "      <td></td>\n",
       "      <td>1,24,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...</td>\n",
       "      <td></td>\n",
       "      <td>82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td></td>\n",
       "      <td>80,950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...</td>\n",
       "      <td></td>\n",
       "      <td>82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 Intel Core i7 10th Gen...</td>\n",
       "      <td></td>\n",
       "      <td>78,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo Yoga 7i 11th Gen Intel Core i7-1165G7 1...</td>\n",
       "      <td></td>\n",
       "      <td>1,06,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS Zenbook 13 OLED, 13.3-inch (33.78 cms) FH...</td>\n",
       "      <td></td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Renewed) HP ELITEBOOK X360 1030 G4 (CORE I7 8...</td>\n",
       "      <td></td>\n",
       "      <td>47,890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Renewed) Lenovo Intel Core i7 5600U 12.5-Inch...</td>\n",
       "      <td></td>\n",
       "      <td>23,997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Renewed) HP Elitebook 840G1-i7-8 GB-2 TB 14-i...</td>\n",
       "      <td></td>\n",
       "      <td>41,690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Ratings     Price\n",
       "0  Acer Spin 5 Professional Laptop with Alexa Bui...          1,24,490\n",
       "1  Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...            82,990\n",
       "2  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....            80,950\n",
       "3  Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...            82,990\n",
       "4  Lenovo IdeaPad Gaming 3 Intel Core i7 10th Gen...            78,990\n",
       "5  Lenovo Yoga 7i 11th Gen Intel Core i7-1165G7 1...          1,06,800\n",
       "6  ASUS Zenbook 13 OLED, 13.3-inch (33.78 cms) FH...            79,990\n",
       "7  (Renewed) HP ELITEBOOK X360 1030 G4 (CORE I7 8...            47,890\n",
       "8  (Renewed) Lenovo Intel Core i7 5600U 12.5-Inch...            23,997\n",
       "9  (Renewed) HP Elitebook 840G1-i7-8 GB-2 TB 14-i...            41,690"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the dataframe from above data\n",
    "df = pd.DataFrame({'Title':Title,'Ratings':Ratings,'Price':Price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2910c8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9386c0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45686357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f91861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88be56f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a9197d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e43a5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01d438c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1cef5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07879418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea82ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a481e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655812b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5136000c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc601dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2de264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a13093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aced7cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b248c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee58b2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a8fd71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c4f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db2fbb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c860056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7293f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d0f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32454df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e5fbad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92852e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96efc65f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428837fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819404f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88414a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4b90dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c2d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
